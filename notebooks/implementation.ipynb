{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d71c729b",
   "metadata": {},
   "source": [
    "# AI-Powered Career Navigation Platform Implementation\n",
    "\n",
    "This notebook demonstrates the implementation of the core components of the Career Navigation Platform.\n",
    "\n",
    "## 1. Install Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7e5425f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: fastapi in c:\\users\\msasw\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (0.104.1)\n",
      "Requirement already satisfied: uvicorn in c:\\users\\msasw\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (0.24.0)\n",
      "Requirement already satisfied: python-multipart in c:\\users\\msasw\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (0.0.6)\n",
      "Requirement already satisfied: openai in c:\\users\\msasw\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (1.3.5)\n",
      "Requirement already satisfied: langchain in c:\\users\\msasw\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (0.0.335)\n",
      "Requirement already satisfied: langchain-google-genai in c:\\users\\msasw\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (1.0.1)\n",
      "Requirement already satisfied: pinecone-client in c:\\users\\msasw\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (2.2.4)\n",
      "Requirement already satisfied: neo4j in c:\\users\\msasw\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (5.14.1)\n",
      "Requirement already satisfied: sentence-transformers in c:\\users\\msasw\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (2.2.2)\n",
      "Requirement already satisfied: spacy in c:\\users\\msasw\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (3.7.2)\n",
      "Requirement already satisfied: redis in c:\\users\\msasw\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (5.0.1)\n",
      "Requirement already satisfied: python-dotenv in c:\\users\\msasw\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (1.0.0)\n",
      "Requirement already satisfied: pydantic in c:\\users\\msasw\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (2.5.0)\n",
      "Requirement already satisfied: anyio<4.0.0,>=3.7.1 in c:\\users\\msasw\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from fastapi) (3.7.1)\n",
      "Requirement already satisfied: starlette<0.28.0,>=0.27.0 in c:\\users\\msasw\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from fastapi) (0.27.0)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\msasw\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from fastapi) (4.15.0)\n",
      "Requirement already satisfied: click>=7.0 in c:\\users\\msasw\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from uvicorn) (8.3.0)\n",
      "Requirement already satisfied: h11>=0.8 in c:\\users\\msasw\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from uvicorn) (0.16.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\msasw\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\msasw\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from openai) (0.25.1)\n",
      "Requirement already satisfied: tqdm>4 in c:\\users\\msasw\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from openai) (4.67.1)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\users\\msasw\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langchain) (6.0.3)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in c:\\users\\msasw\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langchain) (2.0.44)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in c:\\users\\msasw\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langchain) (3.13.2)\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in c:\\users\\msasw\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langchain) (0.6.7)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\users\\msasw\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langchain) (1.33)\n",
      "Requirement already satisfied: langsmith<0.1.0,>=0.0.63 in c:\\users\\msasw\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langchain) (0.0.87)\n",
      "Requirement already satisfied: numpy<2,>=1 in c:\\users\\msasw\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langchain) (1.26.2)\n",
      "Requirement already satisfied: requests<3,>=2 in c:\\users\\msasw\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langchain) (2.32.5)\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in c:\\users\\msasw\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langchain) (8.5.0)\n",
      "Requirement already satisfied: google-generativeai<0.5.0,>=0.4.1 in c:\\users\\msasw\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langchain-google-genai) (0.4.1)\n",
      "Requirement already satisfied: langchain-core<0.2,>=0.1 in c:\\users\\msasw\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langchain-google-genai) (0.1.23)\n",
      "Requirement already satisfied: loguru>=0.5.0 in c:\\users\\msasw\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pinecone-client) (0.7.3)\n",
      "Requirement already satisfied: dnspython>=2.0.0 in c:\\users\\msasw\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pinecone-client) (2.8.0)\n",
      "Requirement already satisfied: python-dateutil>=2.5.3 in c:\\users\\msasw\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pinecone-client) (2.9.0.post0)\n",
      "Requirement already satisfied: urllib3>=1.21.1 in c:\\users\\msasw\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pinecone-client) (2.5.0)\n",
      "Requirement already satisfied: pytz in c:\\users\\msasw\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from neo4j) (2025.2)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.6.0 in c:\\users\\msasw\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from sentence-transformers) (4.35.0)\n",
      "Requirement already satisfied: torch>=1.6.0 in c:\\users\\msasw\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from sentence-transformers) (2.5.1+cu121)\n",
      "Requirement already satisfied: torchvision in c:\\users\\msasw\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from sentence-transformers) (0.20.1+cu121)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\msasw\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from sentence-transformers) (1.3.2)\n",
      "Requirement already satisfied: scipy in c:\\users\\msasw\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from sentence-transformers) (1.16.3)\n",
      "Requirement already satisfied: nltk in c:\\users\\msasw\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from sentence-transformers) (3.9.2)\n",
      "Requirement already satisfied: sentencepiece in c:\\users\\msasw\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from sentence-transformers) (0.2.1)\n",
      "Requirement already satisfied: huggingface-hub>=0.4.0 in c:\\users\\msasw\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from sentence-transformers) (0.17.3)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in c:\\users\\msasw\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from spacy) (3.0.12)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in c:\\users\\msasw\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from spacy) (1.0.5)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in c:\\users\\msasw\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from spacy) (1.0.15)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in c:\\users\\msasw\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from spacy) (2.0.13)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in c:\\users\\msasw\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from spacy) (3.0.12)\n",
      "Requirement already satisfied: thinc<8.3.0,>=8.1.8 in c:\\users\\msasw\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from spacy) (8.2.5)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in c:\\users\\msasw\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from spacy) (1.1.3)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in c:\\users\\msasw\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from spacy) (2.5.2)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in c:\\users\\msasw\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from spacy) (2.0.10)\n",
      "Requirement already satisfied: weasel<0.4.0,>=0.1.0 in c:\\users\\msasw\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from spacy) (0.3.4)\n",
      "Requirement already satisfied: typer<0.10.0,>=0.3.0 in c:\\users\\msasw\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from spacy) (0.9.4)\n",
      "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in c:\\users\\msasw\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from spacy) (6.4.0)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\msasw\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from spacy) (3.1.6)\n",
      "Requirement already satisfied: setuptools in c:\\users\\msasw\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from spacy) (65.5.0)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\msasw\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from spacy) (23.2)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in c:\\users\\msasw\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from spacy) (3.5.0)\n",
      "Requirement already satisfied: async-timeout>=4.0.2 in c:\\users\\msasw\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from redis) (5.0.1)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in c:\\users\\msasw\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pydantic) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.14.1 in c:\\users\\msasw\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pydantic) (2.14.1)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in c:\\users\\msasw\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in c:\\users\\msasw\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\msasw\\appdata\\roaming\\python\\python311\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (25.4.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\msasw\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.8.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\msasw\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.7.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in c:\\users\\msasw\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (0.4.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in c:\\users\\msasw\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.22.0)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\users\\msasw\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from anyio<4.0.0,>=3.7.1->fastapi) (3.11)\n",
      "Requirement already satisfied: sniffio>=1.1 in c:\\users\\msasw\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from anyio<4.0.0,>=3.7.1->fastapi) (1.3.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\msasw\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from click>=7.0->uvicorn) (0.4.6)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in c:\\users\\msasw\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from dataclasses-json<0.7,>=0.5.7->langchain) (3.26.1)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in c:\\users\\msasw\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from dataclasses-json<0.7,>=0.5.7->langchain) (0.9.0)\n",
      "Requirement already satisfied: google-ai-generativelanguage==0.4.0 in c:\\users\\msasw\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from google-generativeai<0.5.0,>=0.4.1->langchain-google-genai) (0.4.0)\n",
      "Requirement already satisfied: google-auth>=2.15.0 in c:\\users\\msasw\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from google-generativeai<0.5.0,>=0.4.1->langchain-google-genai) (2.43.0)\n",
      "Requirement already satisfied: google-api-core in c:\\users\\msasw\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from google-generativeai<0.5.0,>=0.4.1->langchain-google-genai) (2.28.1)\n",
      "Requirement already satisfied: protobuf in c:\\users\\msasw\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from google-generativeai<0.5.0,>=0.4.1->langchain-google-genai) (4.25.8)\n",
      "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in c:\\users\\msasw\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from google-ai-generativelanguage==0.4.0->google-generativeai<0.5.0,>=0.4.1->langchain-google-genai) (1.26.1)\n",
      "Requirement already satisfied: certifi in c:\\users\\msasw\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from httpx<1,>=0.23.0->openai) (2025.10.5)\n",
      "Requirement already satisfied: httpcore in c:\\users\\msasw\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from httpx<1,>=0.23.0->openai) (1.0.9)\n",
      "Requirement already satisfied: filelock in c:\\users\\msasw\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from huggingface-hub>=0.4.0->sentence-transformers) (3.20.0)\n",
      "Requirement already satisfied: fsspec in c:\\users\\msasw\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from huggingface-hub>=0.4.0->sentence-transformers) (2025.9.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\msasw\\appdata\\roaming\\python\\python311\\site-packages (from jsonpatch<2.0,>=1.33->langchain) (3.0.0)\n",
      "Requirement already satisfied: language-data>=1.2 in c:\\users\\msasw\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langcodes<4.0.0,>=3.2.0->spacy) (1.3.0)\n",
      "Requirement already satisfied: win32-setctime>=1.0.0 in c:\\users\\msasw\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from loguru>=0.5.0->pinecone-client) (1.2.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\msasw\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from python-dateutil>=2.5.3->pinecone-client) (1.17.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\msasw\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests<3,>=2->langchain) (3.4.4)\n",
      "Requirement already satisfied: greenlet>=1 in c:\\users\\msasw\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from SQLAlchemy<3,>=1.4->langchain) (3.2.4)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in c:\\users\\msasw\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from thinc<8.3.0,>=8.1.8->spacy) (0.7.11)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in c:\\users\\msasw\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from thinc<8.3.0,>=8.1.8->spacy) (0.1.5)\n",
      "Requirement already satisfied: networkx in c:\\users\\msasw\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch>=1.6.0->sentence-transformers) (3.5)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\users\\msasw\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch>=1.6.0->sentence-transformers) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\msasw\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from sympy==1.13.1->torch>=1.6.0->sentence-transformers) (1.3.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\msasw\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (2025.11.3)\n",
      "Requirement already satisfied: tokenizers<0.15,>=0.14 in c:\\users\\msasw\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (0.14.1)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in c:\\users\\msasw\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (0.6.2)\n",
      "Requirement already satisfied: cloudpathlib<0.17.0,>=0.7.0 in c:\\users\\msasw\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from weasel<0.4.0,>=0.1.0->spacy) (0.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\msasw\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from jinja2->spacy) (3.0.3)\n",
      "Requirement already satisfied: joblib in c:\\users\\msasw\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from nltk->sentence-transformers) (1.5.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\msasw\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from scikit-learn->sentence-transformers) (3.6.0)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\msasw\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torchvision->sentence-transformers) (11.3.0)\n",
      "Requirement already satisfied: cachetools<7.0,>=2.0.0 in c:\\users\\msasw\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from google-auth>=2.15.0->google-generativeai<0.5.0,>=0.4.1->langchain-google-genai) (6.2.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\msasw\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from google-auth>=2.15.0->google-generativeai<0.5.0,>=0.4.1->langchain-google-genai) (0.4.2)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\msasw\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from google-auth>=2.15.0->google-generativeai<0.5.0,>=0.4.1->langchain-google-genai) (4.9.1)\n",
      "Requirement already satisfied: marisa-trie>=1.1.0 in c:\\users\\msasw\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy) (1.3.1)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in c:\\users\\msasw\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain) (1.1.0)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in c:\\users\\msasw\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from google-api-core->google-generativeai<0.5.0,>=0.4.1->langchain-google-genai) (1.72.0)\n",
      "Requirement already satisfied: grpcio<2.0.0,>=1.33.2 in c:\\users\\msasw\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from google-api-core->google-generativeai<0.5.0,>=0.4.1->langchain-google-genai) (1.76.0)\n",
      "Requirement already satisfied: grpcio-status<2.0.0,>=1.33.2 in c:\\users\\msasw\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from google-api-core->google-generativeai<0.5.0,>=0.4.1->langchain-google-genai) (1.62.3)\n",
      "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in c:\\users\\msasw\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth>=2.15.0->google-generativeai<0.5.0,>=0.4.1->langchain-google-genai) (0.6.1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip available: 22.3 -> 25.3\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting https://github.com/explosion/spacy-models/releases/download/-en_core_web_sm/-en_core_web_sm.tar.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  ERROR: HTTP error 404 while getting https://github.com/explosion/spacy-models/releases/download/-en_core_web_sm/-en_core_web_sm.tar.gz\n",
      "ERROR: Could not install requirement https://github.com/explosion/spacy-models/releases/download/-en_core_web_sm/-en_core_web_sm.tar.gz because of HTTP error 404 Client Error: Not Found for url: https://github.com/explosion/spacy-models/releases/download/-en_core_web_sm/-en_core_web_sm.tar.gz for URL https://github.com/explosion/spacy-models/releases/download/-en_core_web_sm/-en_core_web_sm.tar.gz\n",
      "\n",
      "[notice] A new release of pip available: 22.3 -> 25.3\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install fastapi uvicorn python-multipart openai langchain langchain-google-genai pinecone-client neo4j sentence-transformers spacy redis python-dotenv pydantic\n",
    "!python -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bddacdb",
   "metadata": {},
   "source": [
    "## 2. Define Data Models for Resume Parsing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dc55829",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "from typing import List, Optional, Dict\n",
    "\n",
    "class ExtractedSkill(BaseModel):\n",
    "    name: str = Field(description=\"Skill name\")\n",
    "    category: str = Field(description=\"Category: technical, soft, domain\")\n",
    "    proficiency: int = Field(description=\"Estimated proficiency 1-5\")\n",
    "    years_experience: float = Field(description=\"Years of experience with skill\")\n",
    "\n",
    "class ExtractedExperience(BaseModel):\n",
    "    company: str\n",
    "    role: str\n",
    "    duration_months: int\n",
    "    description: str\n",
    "    skills_used: List[str]\n",
    "\n",
    "class ParsedResume(BaseModel):\n",
    "    full_name: str\n",
    "    email: Optional[str]\n",
    "    phone: Optional[str]\n",
    "    current_role: str\n",
    "    years_total_experience: int\n",
    "    skills: List[ExtractedSkill]\n",
    "    experience: List[ExtractedExperience]\n",
    "    education: List[str]\n",
    "    certifications: List[str]\n",
    "    industry: str\n",
    "    summary: str\n",
    "\n",
    "class CareerPathRequest(BaseModel):\n",
    "    current_role: str\n",
    "    target_role: Optional[str] = None\n",
    "    user_skills: List[str]\n",
    "\n",
    "class CareerPathResponse(BaseModel):\n",
    "    paths: List[Dict]\n",
    "    recommended_path: Dict\n",
    "    skill_gaps: Dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cbf61e8",
   "metadata": {},
   "source": [
    "## 3. Implement AI Resume Parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cca03eb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.output_parsers import PydanticOutputParser\n",
    "import PyPDF2\n",
    "import docx\n",
    "import io\n",
    "\n",
    "def extract_text(file_bytes: bytes, filename: str) -> str:\n",
    "    \"\"\"Extract text from PDF or DOCX\"\"\"\n",
    "    if filename.endswith('.pdf'):\n",
    "        return _extract_from_pdf(file_bytes)\n",
    "    elif filename.endswith('.docx'):\n",
    "        return _extract_from_docx(file_bytes)\n",
    "    else:\n",
    "        return file_bytes.decode('utf-8')\n",
    "\n",
    "def _extract_from_pdf(file_bytes: bytes) -> str:\n",
    "    pdf_reader = PyPDF2.PdfReader(io.BytesIO(file_bytes))\n",
    "    text = \"\"\n",
    "    for page in pdf_reader.pages:\n",
    "        text += page.extract_text()\n",
    "    return text\n",
    "\n",
    "def _extract_from_docx(file_bytes: bytes) -> str:\n",
    "    doc = docx.Document(io.BytesIO(file_bytes))\n",
    "    return \"\\n\".join([para.text for para in doc.paragraphs])\n",
    "\n",
    "class AIResumeParser:\n",
    "    def __init__(self, google_api_key: str):\n",
    "        self.llm = ChatGoogleGenerativeAI(\n",
    "            model=\"gemini-pro\",\n",
    "            temperature=0.1,\n",
    "            google_api_key=google_api_key\n",
    "        )\n",
    "        self.parser = PydanticOutputParser(pydantic_object=ParsedResume)\n",
    "    \n",
    "    async def parse_resume(self, resume_text: str) -> ParsedResume:\n",
    "        \"\"\"Parse resume using Gemini Pro\"\"\"\n",
    "        \n",
    "        prompt = ChatPromptTemplate.from_messages([\n",
    "            (\"system\", \"\"\"You are an expert resume parser. Extract structured information \n",
    "            from resumes accurately. For skills, categorize them and estimate proficiency \n",
    "            based on context (junior/senior role, years of experience mentioned).\n",
    "            \n",
    "            {format_instructions}\n",
    "            \"\"\"),\n",
    "            (\"user\", \"Parse this resume:\\n\\n{resume_text}\")\n",
    "        ])\n",
    "        \n",
    "        chain = prompt | self.llm | self.parser\n",
    "        \n",
    "        result = await chain.ainvoke({\n",
    "            \"resume_text\": resume_text,\n",
    "            \"format_instructions\": self.parser.get_format_instructions()\n",
    "        })\n",
    "        \n",
    "        return result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9c52c4c",
   "metadata": {},
   "source": [
    "## 4. Create Vector Database Service for Skill Matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93807a84",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pinecone\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import numpy as np\n",
    "\n",
    "class SkillVectorDB:\n",
    "    def __init__(self, pinecone_api_key: str, index_name: str = \"career-skills\"):\n",
    "        # Initialize Pinecone\n",
    "        pinecone.init(api_key=pinecone_api_key, environment=\"us-west1-gcp\")\n",
    "        \n",
    "        # Create or connect to index\n",
    "        if index_name not in pinecone.list_indexes():\n",
    "            pinecone.create_index(\n",
    "                index_name,\n",
    "                dimension=384,  # all-MiniLM-L6-v2 embedding size\n",
    "                metric=\"cosine\"\n",
    "            )\n",
    "        \n",
    "        self.index = pinecone.Index(index_name)\n",
    "        \n",
    "        # Load sentence transformer model\n",
    "        self.model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "    \n",
    "    def add_skills(self, skills: List[Dict]):\n",
    "        \"\"\"Add skills to vector database\"\"\"\n",
    "        vectors = []\n",
    "        for skill in skills:\n",
    "            # Generate embedding\n",
    "            embedding = self.model.encode(skill['name']).tolist()\n",
    "            \n",
    "            vectors.append({\n",
    "                'id': skill['id'],\n",
    "                'values': embedding,\n",
    "                'metadata': {\n",
    "                    'name': skill['name'],\n",
    "                    'category': skill.get('category', 'general'),\n",
    "                    'demand_score': skill.get('demand_score', 50)\n",
    "                }\n",
    "            })\n",
    "        \n",
    "        # Upsert to Pinecone\n",
    "        self.index.upsert(vectors=vectors)\n",
    "    \n",
    "    def find_similar_skills(self, skill_name: str, top_k: int = 5) -> List[Dict]:\n",
    "        \"\"\"Find semantically similar skills\"\"\"\n",
    "        \n",
    "        # Generate query embedding\n",
    "        query_embedding = self.model.encode(skill_name).tolist()\n",
    "        \n",
    "        # Search in Pinecone\n",
    "        results = self.index.query(\n",
    "            vector=query_embedding,\n",
    "            top_k=top_k,\n",
    "            include_metadata=True\n",
    "        )\n",
    "        \n",
    "        similar_skills = []\n",
    "        for match in results['matches']:\n",
    "            similar_skills.append({\n",
    "                'skill': match['metadata']['name'],\n",
    "                'category': match['metadata']['category'],\n",
    "                'similarity_score': match['score'],\n",
    "                'demand_score': match['metadata']['demand_score']\n",
    "            })\n",
    "        \n",
    "        return similar_skills\n",
    "    \n",
    "    def match_user_skills_to_role(self, user_skills: List[str], \n",
    "                                   role_required_skills: List[str]) -> Dict:\n",
    "        \"\"\"Match user skills against role requirements\"\"\"\n",
    "        \n",
    "        matched_skills = []\n",
    "        missing_skills = []\n",
    "        \n",
    "        for required_skill in role_required_skills:\n",
    "            # Find if user has similar skill\n",
    "            user_embeddings = self.model.encode(user_skills)\n",
    "            required_embedding = self.model.encode(required_skill)\n",
    "            \n",
    "            # Calculate cosine similarities\n",
    "            similarities = np.dot(user_embeddings, required_embedding) / (\n",
    "                np.linalg.norm(user_embeddings, axis=1) * np.linalg.norm(required_embedding)\n",
    "            )\n",
    "            \n",
    "            max_similarity = similarities.max()\n",
    "            \n",
    "            if max_similarity > 0.7:  # Threshold for \"match\"\n",
    "                matched_idx = similarities.argmax()\n",
    "                matched_skills.append({\n",
    "                    'required': required_skill,\n",
    "                    'user_has': user_skills[matched_idx],\n",
    "                    'match_score': float(max_similarity)\n",
    "                })\n",
    "            else:\n",
    "                missing_skills.append(required_skill)\n",
    "        \n",
    "        match_percentage = (len(matched_skills) / len(role_required_skills)) * 100\n",
    "        \n",
    "        return {\n",
    "            'match_percentage': match_percentage,\n",
    "            'matched_skills': matched_skills,\n",
    "            'missing_skills': missing_skills\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2114ae0",
   "metadata": {},
   "source": [
    "## 5. Create Graph Database Service for Career Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff289c8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from neo4j import GraphDatabase\n",
    "from dataclasses import dataclass\n",
    "\n",
    "@dataclass\n",
    "class CareerPath:\n",
    "    roles: List[str]\n",
    "    total_months: int\n",
    "    avg_difficulty: float\n",
    "    salary_growth: int\n",
    "    required_skills: List[str]\n",
    "\n",
    "class CareerGraphDB:\n",
    "    def __init__(self, uri: str, user: str, password: str):\n",
    "        self.driver = GraphDatabase.driver(uri, auth=(user, password))\n",
    "    \n",
    "    def close(self):\n",
    "        self.driver.close()\n",
    "    \n",
    "    def create_career_graph_schema(self):\n",
    "        \"\"\"Initialize career graph schema\"\"\"\n",
    "        with self.driver.session() as session:\n",
    "            session.run(\"\"\"\n",
    "                CREATE CONSTRAINT role_id IF NOT EXISTS\n",
    "                FOR (r:Role) REQUIRE r.id IS UNIQUE\n",
    "            \"\"\")\n",
    "            session.run(\"\"\"\n",
    "                CREATE CONSTRAINT skill_id IF NOT EXISTS\n",
    "                FOR (s:Skill) REQUIRE s.id IS UNIQUE\n",
    "            \"\"\")\n",
    "    \n",
    "    def add_role(self, role_data: Dict):\n",
    "        \"\"\"Add a career role to graph\"\"\"\n",
    "        with self.driver.session() as session:\n",
    "            session.run(\"\"\"\n",
    "                MERGE (r:Role {id: $id})\n",
    "                SET r.title = $title,\n",
    "                    r.industry = $industry,\n",
    "                    r.level = $level,\n",
    "                    r.avg_salary = $avg_salary,\n",
    "                    r.growth_rate = $growth_rate,\n",
    "                    r.demand_score = $demand_score\n",
    "            \"\"\", **role_data)\n",
    "    \n",
    "    def add_transition(self, from_role_id: str, to_role_id: str, \n",
    "                      transition_data: Dict):\n",
    "        \"\"\"Add career transition relationship\"\"\"\n",
    "        with self.driver.session() as session:\n",
    "            session.run(\"\"\"\n",
    "                MATCH (from:Role {id: $from_id})\n",
    "                MATCH (to:Role {id: $to_id})\n",
    "                MERGE (from)-[t:TRANSITIONS_TO]->(to)\n",
    "                SET t.avg_months = $avg_months,\n",
    "                    t.difficulty = $difficulty,\n",
    "                    t.success_rate = $success_rate,\n",
    "                    t.common_path = $common_path\n",
    "            \"\"\", from_id=from_role_id, to_id=to_role_id, **transition_data)\n",
    "    \n",
    "    def add_skill_requirement(self, role_id: str, skill_id: str, \n",
    "                            proficiency: int, importance: str, skill_name: Optional[str] = None):\n",
    "        \"\"\"Link role to required skill\"\"\"\n",
    "        with self.driver.session() as session:\n",
    "            session.run(\"\"\"\n",
    "                MATCH (r:Role {id: $role_id})\n",
    "                MERGE (s:Skill {id: $skill_id})\n",
    "                ON CREATE SET s.name = $skill_name\n",
    "                MERGE (r)-[req:REQUIRES_SKILL]->(s)\n",
    "                SET req.proficiency = $proficiency,\n",
    "                    req.importance = $importance\n",
    "            \"\"\", role_id=role_id, skill_id=skill_id, \n",
    "                proficiency=proficiency, importance=importance, skill_name=skill_name or skill_id)\n",
    "    \n",
    "    def find_career_paths(self, current_role: str, target_role: Optional[str] = None,\n",
    "                         max_hops: int = 4) -> List[CareerPath]:\n",
    "        \"\"\"Find possible career paths\"\"\"\n",
    "        \n",
    "        with self.driver.session() as session:\n",
    "            if target_role:\n",
    "                query = \"\"\"\n",
    "                    MATCH path = allShortestPaths(\n",
    "                        (current:Role {title: $current})-[:TRANSITIONS_TO*1..$max_hops]->(target:Role {title: $target})\n",
    "                    )\n",
    "                    WITH path, relationships(path) as rels, nodes(path) as roles\n",
    "                    RETURN \n",
    "                        [r in roles | r.title] as role_titles,\n",
    "                        reduce(months = 0, rel in rels | months + rel.avg_months) as total_months,\n",
    "                        reduce(diff = 0, rel in rels | diff + rel.difficulty) / size(rels) as avg_difficulty,\n",
    "                        roles[-1].avg_salary - roles[0].avg_salary as salary_growth\n",
    "                    ORDER BY total_months, avg_difficulty\n",
    "                    LIMIT 10\n",
    "                \"\"\"\n",
    "                result = session.run(query, current=current_role, target=target_role, \n",
    "                                   max_hops=max_hops)\n",
    "            else:\n",
    "                query = \"\"\"\n",
    "                    MATCH path = (current:Role {title: $current})-[:TRANSITIONS_TO*1..$max_hops]->(target:Role)\n",
    "                    WITH path, relationships(path) as rels, nodes(path) as roles\n",
    "                    WHERE size(roles) >= 2\n",
    "                    RETURN DISTINCT\n",
    "                        [r in roles | r.title] as role_titles,\n",
    "                        reduce(months = 0, rel in rels | months + rel.avg_months) as total_months,\n",
    "                        reduce(diff = 0, rel in rels | diff + rel.difficulty) / size(rels) as avg_difficulty,\n",
    "                        roles[-1].avg_salary - roles[0].avg_salary as salary_growth\n",
    "                    ORDER BY salary_growth DESC, total_months ASC\n",
    "                    LIMIT 20\n",
    "                \"\"\"\n",
    "                result = session.run(query, current=current_role, max_hops=max_hops)\n",
    "            \n",
    "            paths = []\n",
    "            for record in result:\n",
    "                target = record['role_titles'][-1]\n",
    "                skills = self._get_role_skills(target)\n",
    "                \n",
    "                paths.append(CareerPath(\n",
    "                    roles=record['role_titles'],\n",
    "                    total_months=record['total_months'],\n",
    "                    avg_difficulty=record['avg_difficulty'],\n",
    "                    salary_growth=record['salary_growth'],\n",
    "                    required_skills=skills\n",
    "                ))\n",
    "            \n",
    "            return paths\n",
    "    \n",
    "    def _get_role_skills(self, role_title: str) -> List[str]:\n",
    "        \"\"\"Get required skills for a role\"\"\"\n",
    "        with self.driver.session() as session:\n",
    "            result = session.run(\"\"\"\n",
    "                MATCH (r:Role {title: $title})-[req:REQUIRES_SKILL]->(s:Skill)\n",
    "                WHERE req.importance IN ['high', 'critical']\n",
    "                RETURN s.name as skill\n",
    "                ORDER BY req.proficiency DESC\n",
    "            \"\"\", title=role_title)\n",
    "            \n",
    "            return [record['skill'] for record in result]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73a04969",
   "metadata": {},
   "source": [
    "## 6. Implement Redis Caching Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d246a9b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import redis.asyncio as redis\n",
    "import json\n",
    "from typing import Any\n",
    "\n",
    "class RedisCache:\n",
    "    def __init__(self, redis_url: str):\n",
    "        self.redis = redis.from_url(redis_url, decode_responses=True)\n",
    "    \n",
    "    async def get(self, key: str) -> Optional[Any]:\n",
    "        \"\"\"Get cached value\"\"\"\n",
    "        value = await self.redis.get(key)\n",
    "        if value:\n",
    "            return json.loads(value)\n",
    "        return None\n",
    "    \n",
    "    async def set(self, key: str, value: Any, expire: int = 3600):\n",
    "        \"\"\"Cache value with expiration\"\"\"\n",
    "        await self.redis.setex(\n",
    "            key,\n",
    "            expire,\n",
    "            json.dumps(value)\n",
    "        )\n",
    "    \n",
    "    async def delete(self, key: str):\n",
    "        \"\"\"Delete cached value\"\"\"\n",
    "        await self.redis.delete(key)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa18a11d",
   "metadata": {},
   "source": [
    "## 7. Configure FastAPI Application and Endpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f87c9fb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastapi import FastAPI, UploadFile, File, HTTPException, Depends\n",
    "from fastapi.middleware.cors import CORSMiddleware\n",
    "import os\n",
    "\n",
    "# Initialize FastAPI\n",
    "app = FastAPI(\n",
    "    title=\"Career Navigation API\",\n",
    "    description=\"AI-powered career path discovery platform\",\n",
    "    version=\"1.0.0\"\n",
    ")\n",
    "\n",
    "# CORS\n",
    "app.add_middleware(\n",
    "    CORSMiddleware,\n",
    "    allow_origins=[\"*\"],\n",
    "    allow_credentials=True,\n",
    "    allow_methods=[\"*\"],\n",
    "    allow_headers=[\"*\"],\n",
    ")\n",
    "\n",
    "# Initialize services (Mocking env vars for notebook if needed, or assume .env is loaded)\n",
    "# In a real notebook run, you would set these variables or load from .env\n",
    "os.environ[\"GOOGLE_API_KEY\"] = \"your-key\"\n",
    "os.environ[\"PINECONE_API_KEY\"] = \"your-key\"\n",
    "os.environ[\"NEO4J_URI\"] = \"bolt://localhost:7687\"\n",
    "os.environ[\"NEO4J_USER\"] = \"neo4j\"\n",
    "os.environ[\"NEO4J_PASSWORD\"] = \"password\"\n",
    "os.environ[\"REDIS_URL\"] = \"redis://localhost:6379\"\n",
    "\n",
    "resume_parser = AIResumeParser(google_api_key=os.getenv(\"GOOGLE_API_KEY\"))\n",
    "skill_db = SkillVectorDB(pinecone_api_key=os.getenv(\"PINECONE_API_KEY\"))\n",
    "career_graph = CareerGraphDB(\n",
    "    uri=os.getenv(\"NEO4J_URI\"),\n",
    "    user=os.getenv(\"NEO4J_USER\"),\n",
    "    password=os.getenv(\"NEO4J_PASSWORD\")\n",
    ")\n",
    "cache = RedisCache(redis_url=os.getenv(\"REDIS_URL\"))\n",
    "\n",
    "def calculate_path_score(path: Dict) -> float:\n",
    "    \"\"\"Calculate overall path score\"\"\"\n",
    "    weights = {\n",
    "        'skill_match': 0.4,\n",
    "        'salary_growth': 0.3,\n",
    "        'timeline': 0.2,\n",
    "        'difficulty': 0.1\n",
    "    }\n",
    "    \n",
    "    # Normalize values\n",
    "    skill_score = path['skill_match'] / 100\n",
    "    salary_score = min(path['salary_growth'] / 50000, 1.0)\n",
    "    timeline_score = 1 - (path['timeline_months'] / 60)\n",
    "    difficulty_score = 1 - (path['difficulty'] / 10)\n",
    "    \n",
    "    return (\n",
    "        weights['skill_match'] * skill_score +\n",
    "        weights['salary_growth'] * salary_score +\n",
    "        weights['timeline'] * timeline_score +\n",
    "        weights['difficulty'] * difficulty_score\n",
    "    )\n",
    "\n",
    "@app.post(\"/api/v1/resume/parse\", response_model=ParsedResume)\n",
    "async def parse_resume(file: UploadFile = File(...)):\n",
    "    \"\"\"Parse uploaded resume\"\"\"\n",
    "    try:\n",
    "        # Read file\n",
    "        contents = await file.read()\n",
    "        \n",
    "        # Check cache\n",
    "        cache_key = f\"resume:{file.filename}\"\n",
    "        cached = await cache.get(cache_key)\n",
    "        if cached:\n",
    "            return cached\n",
    "        \n",
    "        # Parse resume\n",
    "        text = extract_text(contents, file.filename)\n",
    "        parsed_data = await resume_parser.parse_resume(text)\n",
    "        \n",
    "        # Cache result\n",
    "        await cache.set(cache_key, parsed_data.dict(), expire=3600)\n",
    "        \n",
    "        return parsed_data\n",
    "    \n",
    "    except Exception as e:\n",
    "        raise HTTPException(status_code=500, detail=str(e))\n",
    "\n",
    "@app.post(\"/api/v1/career-paths\", response_model=CareerPathResponse)\n",
    "async def get_career_paths(request: CareerPathRequest):\n",
    "    \"\"\"Get personalized career paths\"\"\"\n",
    "    try:\n",
    "        # Find paths in graph\n",
    "        paths = career_graph.find_career_paths(\n",
    "            current_role=request.current_role,\n",
    "            target_role=request.target_role\n",
    "        )\n",
    "        \n",
    "        # Analyze skill gaps for each path\n",
    "        analyzed_paths = []\n",
    "        for path in paths:\n",
    "            skill_gap = skill_db.match_user_skills_to_role(\n",
    "                user_skills=request.user_skills,\n",
    "                role_required_skills=path.required_skills\n",
    "            )\n",
    "            \n",
    "            analyzed_paths.append({\n",
    "                'roles': path.roles,\n",
    "                'timeline_months': path.total_months,\n",
    "                'difficulty': path.avg_difficulty,\n",
    "                'salary_growth': path.salary_growth,\n",
    "                'skill_match': skill_gap['match_percentage'],\n",
    "                'missing_skills': skill_gap['missing_skills']\n",
    "            })\n",
    "        \n",
    "        # Rank paths by overall score\n",
    "        for path in analyzed_paths:\n",
    "            path['score'] = calculate_path_score(path)\n",
    "        \n",
    "        analyzed_paths.sort(key=lambda x: x['score'], reverse=True)\n",
    "        \n",
    "        return {\n",
    "            'paths': analyzed_paths,\n",
    "            'recommended_path': analyzed_paths[0] if analyzed_paths else None,\n",
    "            'skill_gaps': skill_gap\n",
    "        }\n",
    "    \n",
    "    except Exception as e:\n",
    "        raise HTTPException(status_code=500, detail=str(e))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdb4182f",
   "metadata": {},
   "source": [
    "## 8. Run Integrated Career Navigation Workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3179fd2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "\n",
    "async def main():\n",
    "    print(\"Starting Career Navigation Workflow...\")\n",
    "    \n",
    "    # 1. Parse Resume (Mocking file upload)\n",
    "    # In a real scenario, you would upload a file. Here we simulate the text extraction.\n",
    "    print(\"\\n1. Parsing Resume...\")\n",
    "    # Mock resume text for demonstration if no file is available\n",
    "    resume_text = \"\"\"\n",
    "    John Doe\n",
    "    Software Engineer\n",
    "    Experience:\n",
    "    - Junior Developer at TechCorp (2 years)\n",
    "      Skills: Python, Java, SQL\n",
    "    - Software Engineer at BigData Inc (3 years)\n",
    "      Skills: Python, FastAPI, React, Docker\n",
    "    \"\"\"\n",
    "    \n",
    "    # We can call the parser directly with text\n",
    "    # parsed_resume = await resume_parser.parse_resume(resume_text)\n",
    "    \n",
    "    # Mocking parsed result to avoid API calls in this demo if keys are not set\n",
    "    print(\"Parsed Resume: John Doe\")\n",
    "    print(\"Current Role: Software Engineer\")\n",
    "    user_skills = [\"Python\", \"FastAPI\", \"React\", \"Docker\", \"SQL\", \"Java\"]\n",
    "    print(f\"Skills: {user_skills}\")\n",
    "    \n",
    "    # 2. Find Career Paths\n",
    "    print(\"\\n2. Finding Career Paths...\")\n",
    "    # Ensure graph DB is connected or mock the response\n",
    "    try:\n",
    "        paths = career_graph.find_career_paths(\n",
    "            current_role=\"Software Engineer\",\n",
    "            target_role=\"Senior Software Engineer\" # Using a role we seeded\n",
    "        )\n",
    "        \n",
    "        print(f\"Found {len(paths)} career paths:\")\n",
    "        for i, path in enumerate(paths, 1):\n",
    "            print(f\"\\nPath {i}:\")\n",
    "            print(f\"  Roles: {' -> '.join(path.roles)}\")\n",
    "            print(f\"  Timeline: {path.total_months} months\")\n",
    "            print(f\"  Difficulty: {path.avg_difficulty}/10\")\n",
    "            print(f\"  Salary Growth: ${path.salary_growth}\")\n",
    "            \n",
    "            # 3. Analyze Skill Gap for this path\n",
    "            print(f\"  Analyzing Skill Gap...\")\n",
    "            # Ensure vector DB is connected or mock\n",
    "            try:\n",
    "                gap_analysis = skill_db.match_user_skills_to_role(user_skills, path.required_skills)\n",
    "                print(f\"  Skill Match: {gap_analysis['match_percentage']:.1f}%\")\n",
    "                print(f\"  Missing Skills: {gap_analysis['missing_skills']}\")\n",
    "            except Exception as e:\n",
    "                print(f\"  Vector DB Error: {e}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Graph DB Error: {e}\")\n",
    "        print(\"Ensure Neo4j is running and seeded.\")\n",
    "\n",
    "# Run the workflow\n",
    "# await main() # Uncomment to run in Jupyter\n",
    "print(\"Workflow defined. Uncomment 'await main()' to run.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
